## 5. Implementa√ß√£o Pr√°tica com Sentence-Transformers

### üéØ **Por que Sentence-Transformers?**

O **Sentence-Transformers** √© uma biblioteca Python que facilita o uso de modelos pr√©-treinados para gerar embeddings de alta qualidade. Diferente de embeddings de palavras individuais (Word2Vec), ele gera embeddings para **frases e documentos completos**.

**Vantagens:**
- üöÄ **Plug-and-play**: Modelos pr√©-treinados prontos para uso
- üéØ **Sem√¢ntica contextual**: Entende o significado completo das frases
- üåç **Multil√≠ngue**: Suporte a diversos idiomas
- ‚ö° **Eficiente**: Otimizado para produ√ß√£o

### 5.1 Sistema de Busca com Embeddings

```python
from sentence_transformers import SentenceTransformer
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import pickle
from typing import List, Tuple, Dict
import uuid

class EmbeddingSearchSystem:
    """
    üîç Sistema de Busca Sem√¢ntica com Embeddings
    
    Este sistema demonstra como construir um mecanismo de busca que entende
    o SIGNIFICADO do texto, n√£o apenas palavras-chave exatas.
    
    Exemplo: Buscar por "cachorro" tamb√©m encontrar√° textos sobre "c√£o" ou "pet"
    """
    
    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):
        """
        üèóÔ∏è Inicializa√ß√£o do Sistema
        
        Args:
            model_name: Nome do modelo Sentence-Transformers
            
        üìä Modelos Populares:
        - 'all-MiniLM-L6-v2': R√°pido, 384 dimens√µes, boa qualidade geral
        - 'all-mpnet-base-v2': Melhor qualidade, 768 dimens√µes, mais lento  
        - 'paraphrase-multilingual': Suporte multil√≠ngue
        """
        print(f"üîÑ Carregando modelo: {model_name}")
        self.model = SentenceTransformer(model_name)
        
        # üìö Estruturas de dados do sistema
        self.documents = {}      # doc_id -> {text, metadata}
        self.embeddings = {}     # doc_id -> embedding_vector  
        self.document_ids = []   # Lista ordenada de IDs
        
        print(f"‚úÖ Sistema inicializado com modelo {model_name}")
        print(f"üìê Dimens√µes dos embeddings: {self.model.get_sentence_embedding_dimension()}")
    
    def add_document(self, text: str, metadata: Dict = None) -> str:
        """
        ‚ûï Adicionar Documento ao Sistema
        
        Processo:
        1. Gera ID √∫nico para o documento
        2. Armazena texto e metadados  
        3. Converte texto em embedding vetorial
        4. Armazena embedding para buscas futuras
        
        Args:
            text: Texto do documento
            metadata: Informa√ß√µes adicionais (categoria, autor, etc.)
            
        Returns:
            doc_id: Identificador √∫nico do documento
        """
        doc_id = str(uuid.uuid4())
        print(f"üìù Adicionando documento: {doc_id[:8]}...")
        
        # üíæ Armazenar documento e metadados
        self.documents[doc_id] = {
            'text': text,
            'metadata': metadata or {}
        }
        
        # üß† Gerar embedding (convers√£o texto ‚Üí vetor)
        print(f"üîÑ Gerando embedding para: '{text[:50]}...'")
        embedding = self.model.encode([text])[0]
        self.embeddings[doc_id] = embedding
        self.document_ids.append(doc_id)
        
        print(f"‚úÖ Documento adicionado com {len(embedding)} dimens√µes")
        return doc_id
    
    def remove_document(self, doc_id: str) -> bool:
        """
        üóëÔ∏è Remover Documento do Sistema
        
        Remove completamente o documento de todas as estruturas:
        - Texto e metadados
        - Embedding vetorial
        - Lista de IDs
        """
        if doc_id in self.documents:
            print(f"üóëÔ∏è Removendo documento: {doc_id[:8]}...")
            
            del self.documents[doc_id]
            del self.embeddings[doc_id] 
            self.document_ids.remove(doc_id)
            
            print("‚úÖ Documento removido com sucesso")
            return True
        
        print("‚ùå Documento n√£o encontrado")
        return False
    
    def search(self, query: str, top_k: int = 5) -> List[Tuple[str, float, str]]:
        """
        üîç Buscar Documentos Similares
        
        Algoritmo de Busca Sem√¢ntica:
        1. Converte consulta em embedding
        2. Calcula similaridade cosseno com todos os documentos
        3. Ordena por similaridade (maior = mais relevante)
        4. Retorna top_k mais similares
        
        Args:
            query: Texto da consulta
            top_k: N√∫mero m√°ximo de resultados
            
        Returns:
            Lista de tuplas: (doc_id, similaridade, texto)
        """
        if not self.documents:
            print("‚ö†Ô∏è Nenhum documento no sistema")
            return []
        
        print(f"üîç Buscando por: '{query}'")
        
        # üß† Converter consulta em embedding
        query_embedding = self.model.encode([query])[0]
        
        # üìä Calcular similaridade com todos os documentos
        similarities = []
        for doc_id in self.document_ids:
            doc_embedding = self.embeddings[doc_id]
            
            # üìê Similaridade cosseno: mede √¢ngulo entre vetores
            # Valores: -1 (opostos) a 1 (id√™nticos)
            similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]
            similarities.append((doc_id, similarity, self.documents[doc_id]['text']))
        
        # üìà Ordenar por relev√¢ncia (similaridade decrescente)
        similarities.sort(key=lambda x: x[1], reverse=True)
        
        print(f"üìä Encontrados {len(similarities)} documentos")
        return similarities[:top_k]
    
    def update_document(self, doc_id: str, new_text: str, new_metadata: Dict = None):
        """
        üîÑ Atualizar Documento Existente
        
        Importante: Quando o texto muda, o embedding DEVE ser recalculado
        porque a representa√ß√£o vetorial mudou!
        """
        if doc_id in self.documents:
            print(f"üîÑ Atualizando documento: {doc_id[:8]}...")
            
            # Atualizar texto e metadata
            self.documents[doc_id]['text'] = new_text
            if new_metadata:
                self.documents[doc_id]['metadata'].update(new_metadata)
            
            # üß† CR√çTICO: Regenerar embedding para novo texto
            embedding = self.model.encode([new_text])[0]
            self.embeddings[doc_id] = embedding
            
            print("‚úÖ Documento e embedding atualizados")
            return True
        
        print("‚ùå Documento n√£o encontrado")
        return False
    
    def save_system(self, filepath: str):
        """
        üíæ Persistir Sistema em Arquivo
        
        Salva todo o estado do sistema:
        - Documentos e metadados
        - Embeddings pr√©-computados (economiza tempo!)
        - Lista de IDs
        
        ‚ö†Ô∏è Nota: O modelo n√£o √© salvo - deve ser recarregado na inicializa√ß√£o
        """
        print(f"üíæ Salvando sistema em: {filepath}")
        
        system_data = {
            'documents': self.documents,
            'embeddings': self.embeddings,
            'document_ids': self.document_ids
        }
        
        with open(filepath, 'wb') as f:
            pickle.dump(system_data, f)
        
        print(f"‚úÖ Sistema salvo com {len(self.documents)} documentos")
    
    def load_system(self, filepath: str):
        """
        üìÇ Carregar Sistema de Arquivo
        
        Restaura estado completo do sistema, incluindo embeddings
        pr√©-computados (evita recalcular tudo!)
        """
        print(f"üìÇ Carregando sistema de: {filepath}")
        
        with open(filepath, 'rb') as f:
            system_data = pickle.load(f)
        
        self.documents = system_data['documents']
        self.embeddings = system_data['embeddings']
        self.document_ids = system_data['document_ids']
        
        print(f"‚úÖ Sistema carregado com {len(self.documents)} documentos")

# üöÄ EXEMPLO PR√ÅTICO EDUCACIONAL
def exemplo_sistema_busca():
    """
    üìö Demonstra√ß√£o Completa do Sistema de Busca Sem√¢ntica
    
    Este exemplo mostra:
    1. Como inicializar o sistema
    2. Adicionar documentos com metadados
    3. Realizar buscas sem√¢nticas
    4. Interpretar resultados de similaridade
    5. Gerenciar documentos (adicionar/remover)
    """
    
    print("=" * 60)
    print("üéì DEMONSTRA√á√ÉO: SISTEMA DE BUSCA SEM√ÇNTICA")
    print("=" * 60)
    
    # üèóÔ∏è Inicializar sistema
    search_system = EmbeddingSearchSystem()
    
    # üìö Conjunto de documentos sobre tecnologia
    documentos = [
        "Python √© uma linguagem de programa√ß√£o vers√°til e f√°cil de aprender.",
        "Machine Learning utiliza algoritmos para encontrar padr√µes em dados.",
        "Embeddings convertem texto em representa√ß√µes vetoriais densas.",
        "Deep Learning √© um subcampo do Machine Learning que usa redes neurais.",
        "Natural Language Processing permite que computadores entendam texto humano."
    ]
    
    print(f"\nüìù Adicionando {len(documentos)} documentos...")
    doc_ids = []
    for i, doc in enumerate(documentos):
        doc_id = search_system.add_document(
            doc, 
            {'categoria': 'tecnologia', 'indice': i}
        )
        doc_ids.append(doc_id)
    
    # üîç Demonstrar buscas sem√¢nticas
    queries = [
        "aprendizado de m√°quina",      # Deve encontrar ML e DL
        "programa√ß√£o em Python",       # Deve encontrar Python
        "processamento de texto"       # Deve encontrar NLP
    ]
    
    print(f"\nüîç Realizando {len(queries)} buscas sem√¢nticas...")
    for query in queries:
        print(f"\n{'='*50}")
        print(f"üîç Consulta: '{query}'")
        print('='*50)
        
        results = search_system.search(query, top_k=3)
        
        for i, (doc_id, similarity, text) in enumerate(results):
            print(f"\n{i+1}. üìä Similaridade: {similarity:.3f}")
            print(f"   üìù Texto: {text}")
            print(f"   üÜî ID: {doc_id[:8]}...")
            
            # üí° Interpreta√ß√£o educacional da similaridade
            if similarity > 0.7:
                print("   ‚úÖ Alta relev√¢ncia")
            elif similarity > 0.5:
                print("   üü° Relev√¢ncia moderada")
            else:
                print("   üî¥ Baixa relev√¢ncia")
    
    # üóëÔ∏è Demonstrar remo√ß√£o de documento
    print(f"\n{'='*50}")
    print("üóëÔ∏è DEMONSTRA√á√ÉO: REMO√á√ÉO DE DOCUMENTO")
    print('='*50)
    
    print(f"Removendo documento: {doc_ids[0][:8]}...")
    search_system.remove_document(doc_ids[0])
    
    # üîç Busca ap√≥s remo√ß√£o
    print(f"\nüîç Busca ap√≥s remo√ß√£o por: 'Python'")
    results = search_system.search("Python", top_k=3)
    
    print(f"üìä Resultados encontrados: {len(results)}")
    for i, (doc_id, similarity, text) in enumerate(results):
        print(f"{i+1}. Similaridade: {similarity:.3f}")
        print(f"   {text[:60]}...")
    
    # üíæ Demonstrar persist√™ncia
    print(f"\n{'='*50}")
    print("üíæ DEMONSTRA√á√ÉO: SALVAR/CARREGAR SISTEMA")
    print('='*50)
    
    filename = "sistema_busca.pkl"
    search_system.save_system(filename)
    
    # Criar novo sistema e carregar dados
    novo_sistema = EmbeddingSearchSystem()
    novo_sistema.load_system(filename)
    
    print("‚úÖ Sistema recarregado com sucesso!")
    
    # üìä Estat√≠sticas finais
    print(f"\n{'='*50}")
    print("üìä ESTAT√çSTICAS DO SISTEMA")
    print('='*50)
    print(f"üìö Total de documentos: {len(search_system.documents)}")
    print(f"üß† Dimens√µes dos embeddings: {len(list(search_system.embeddings.values())[0])}")
    print(f"üíæ Tamanho m√©dio dos embeddings: {np.mean([emb.nbytes for emb in search_system.embeddings.values()])} bytes")

# üéØ PONTOS-CHAVE PARA FIXA√á√ÉO
def pontos_chave_educacionais():
    """
    üìù Conceitos Fundamentais Demonstrados
    """
    print("\n" + "="*60)
    print("üéØ CONCEITOS-CHAVE APRENDIDOS")
    print("="*60)
    
    conceitos = [
        "üîç Busca Sem√¢ntica: Encontra significado, n√£o apenas palavras exatas",
        "üìä Similaridade Cosseno: Mede √¢ngulo entre vetores (0-1 para embeddings normalizados)",
        "üß† Embeddings Contextuais: Capturam significado completo de frases/documentos",
        "üíæ Persist√™ncia: Salvar embeddings evita rec√°lculos custosos",
        "üîÑ Atualiza√ß√£o Din√¢mica: Texto novo = embedding novo",
        "üìà Ranking por Relev√¢ncia: Ordena√ß√£o por similaridade decrescente"
    ]
    
    for conceito in conceitos:
        print(f"  {conceito}")
    
    print(f"\nüí° DICA PR√ÅTICA:")
    print("  Em produ√ß√£o, use √≠ndices aproximados (FAISS, Annoy) para")
    print("  buscas r√°pidas em milh√µes de documentos!")

# üöÄ Executar demonstra√ß√£o completa
if __name__ == "__main__":
    exemplo_sistema_busca()
    pontos_chave_educacionais()
```

## 5.2 Sistema Avan√ßado com Chunking

### üéØ **Conceitos Fundamentais**

Este sistema demonstra como lidar com **documentos longos** em aplica√ß√µes reais de NLP, onde textos excedem os limites de processamento de modelos de linguagem.

**Por que precisamos de chunking?**
- **Limita√ß√µes de modelos**: GPT-3.5 (4K tokens), BERT (512 tokens)
- **Qualidade de busca**: Chunks menores = resultados mais precisos
- **Performance**: Processamento paralelo de fragmentos independentes

```python
from sentence_transformers import SentenceTransformer
from typing import Dict, List
import uuid

class AdvancedEmbeddingSystem:
    def __init__(self, model_name: str = 'all-MiniLM-L6-v2', chunk_size: int = 512):
        """
        üèóÔ∏è INICIALIZA√á√ÉO DO SISTEMA AVAN√áADO
        
        Args:
            model_name: Modelo de embedding (all-MiniLM-L6-v2 = r√°pido e eficiente)
            chunk_size: Tamanho m√°ximo dos chunks em caracteres
        
        üí° Escolha do modelo:
        - all-MiniLM-L6-v2: 384 dimens√µes, r√°pido, boa qualidade geral
        - all-mpnet-base-v2: 768 dimens√µes, melhor qualidade, mais lento
        - multilingual: Para textos em m√∫ltiplos idiomas
        """
        self.model = SentenceTransformer(model_name)
        self.chunker = DocumentChunker(chunk_size=chunk_size)
        self.search_system = EmbeddingSearchSystem(model_name)
    
    def add_long_document(self, text: str, doc_title: str = None, metadata: Dict = None) -> List[str]:
        """
        üìÑ PROCESSAMENTO DE DOCUMENTOS LONGOS
        
        Esta fun√ß√£o resolve o problema fundamental: como processar textos
        que excedem os limites dos modelos de linguagem?
        
        Estrat√©gia:
        1. Dividir documento em chunks menores
        2. Gerar embedding para cada chunk
        3. Manter rastreabilidade (qual chunk pertence a qual documento)
        
        Returns:
            Lista de IDs dos chunks criados
        """
        # ETAPA 1: Divis√£o inteligente do documento
        chunks = self.chunker.chunk_by_sentences(text)
        chunk_ids = []
        
        # ETAPA 2: Processar cada chunk individualmente
        for i, chunk in enumerate(chunks):
            # üè∑Ô∏è METADADOS ENRIQUECIDOS
            # Preservar informa√ß√£o sobre origem e posi√ß√£o do chunk
            chunk_metadata = metadata.copy() if metadata else {}
            chunk_metadata.update({
                'document_title': doc_title or f'Document_{len(self.search_system.documents)}',
                'chunk_index': i,                    # Posi√ß√£o no documento original
                'total_chunks': len(chunks),         # Total de chunks do documento
                'is_chunk': True                     # Flag para identificar chunks
            })
            
            # ETAPA 3: Adicionar chunk ao sistema de busca
            chunk_id = self.search_system.add_document(chunk, chunk_metadata)
            chunk_ids.append(chunk_id)
        
        return chunk_ids
    
    def search_with_context(self, query: str, top_k: int = 5) -> List[Dict]:
        """
        üîç BUSCA CONTEXTUALIZADA
        
        Diferencial: Al√©m da similaridade, retorna informa√ß√µes contextuais
        que ajudam o usu√°rio a entender de onde veio o resultado.
        
        Informa√ß√µes contextuais incluem:
        - T√≠tulo do documento original
        - Posi√ß√£o do chunk no documento
        - Metadados adicionais
        """
        # ETAPA 1: Busca sem√¢ntica tradicional
        results = self.search_system.search(query, top_k)
        
        # ETAPA 2: Enriquecimento com contexto
        contextualized_results = []
        for doc_id, similarity, text in results:
            doc_info = self.search_system.documents[doc_id]
            
            # üìä ESTRUTURA DE RESULTADO ENRIQUECIDA
            result = {
                'id': doc_id,
                'text': text,
                'similarity': similarity,
                'metadata': doc_info['metadata']
            }
            
            # üîó ADICIONAR CONTEXTO PARA CHUNKS
            if doc_info['metadata'].get('is_chunk', False):
                result['document_title'] = doc_info['metadata'].get('document_title')
                result['chunk_position'] = f"{doc_info['metadata']['chunk_index'] + 1}/{doc_info['metadata']['total_chunks']}"
            
            contextualized_results.append(result)
        
        return contextualized_results
```

### üöÄ **Exemplo Pr√°tico Educacional**

```python
def exemplo_documento_longo():
    """
    üìö DEMONSTRA√á√ÉO COMPLETA: DO DOCUMENTO LONGO √Ä BUSCA INTELIGENTE
    
    Este exemplo simula um cen√°rio real onde voc√™ tem:
    - Um documento extenso sobre IA
    - Necessidade de fazer buscas espec√≠ficas
    - Import√¢ncia de manter contexto dos resultados
    """
    
    print("üéì INICIANDO SISTEMA AVAN√áADO DE EMBEDDINGS")
    print("=" * 60)
    
    # üèóÔ∏è CONFIGURA√á√ÉO DO SISTEMA
    advanced_system = AdvancedEmbeddingSystem(chunk_size=200)
    
    # üìÑ DOCUMENTO DE EXEMPLO (simulando artigo cient√≠fico)
    documento_longo = """
    A intelig√™ncia artificial (IA) √© uma √°rea da ci√™ncia da computa√ß√£o que se concentra 
    na cria√ß√£o de sistemas capazes de realizar tarefas que normalmente requerem 
    intelig√™ncia humana. Isso inclui aprendizado, racioc√≠nio, percep√ß√£o, 
    processamento de linguagem natural e tomada de decis√µes.
    
    O machine learning √© um subcampo da IA que permite que os computadores aprendam 
    e melhorem automaticamente atrav√©s da experi√™ncia, sem serem explicitamente 
    programados para cada tarefa espec√≠fica. Os algoritmos de machine learning 
    constroem modelos baseados em dados de treinamento para fazer previs√µes 
    ou tomar decis√µes.
    
    Deep learning, por sua vez, √© um subcampo do machine learning que utiliza 
    redes neurais artificiais com m√∫ltiplas camadas para modelar e compreender 
    dados complexos. Essas redes s√£o inspiradas no funcionamento do c√©rebro humano 
    e s√£o especialmente eficazes em tarefas como reconhecimento de imagem, 
    processamento de linguagem natural e reconhecimento de fala.
    
    Os embeddings s√£o uma t√©cnica fundamental utilizada em muitas aplica√ß√µes 
    de IA e NLP. Eles convertem dados categ√≥ricos ou textuais em representa√ß√µes 
    vetoriais densas que capturam rela√ß√µes sem√¢nticas. Isso permite que algoritmos 
    de machine learning trabalhem mais efetivamente com dados textuais, 
    encontrando padr√µes e similaridades que n√£o seriam √≥bvios em representa√ß√µes 
    mais simples.
    """
    
    # üì• PROCESSAMENTO DO DOCUMENTO
    print("üì• Processando documento longo...")
    chunk_ids = advanced_system.add_long_document(
        documento_longo, 
        "Introdu√ß√£o √† Intelig√™ncia Artificial",
        {'autor': 'Sistema de Exemplos', 'categoria': 'educacional'}
    )
    
    print(f"‚úÖ Documento dividido em {len(chunk_ids)} chunks")
    print(f"üìä IDs dos chunks: {chunk_ids[:3]}..." if len(chunk_ids) > 3 else f"üìä IDs: {chunk_ids}")
    
    # üîç DEMONSTRA√á√ÉO DE BUSCAS DIVERSIFICADAS
    queries = [
        "redes neurais",              # Busca por conceito espec√≠fico
        "machine learning algoritmos", # Busca por √°rea + m√©todo
        "embeddings sem√¢ntica"        # Busca por t√©cnica + propriedade
    ]
    
    print(f"\nüéØ Realizando {len(queries)} buscas demonstrativas...")
    
    for query_idx, query in enumerate(queries, 1):
        print(f"\n{'='*50}")
        print(f"üîç BUSCA {query_idx}: '{query}'")
        print('='*50)
        
        # üöÄ EXECUTAR BUSCA CONTEXTUALIZADA
        results = advanced_system.search_with_context(query, top_k=3)
        
        if not results:
            print("‚ùå Nenhum resultado encontrado")
            continue
        
        # üìä AN√ÅLISE DOS RESULTADOS
        print(f"üìà {len(results)} resultados encontrados:")
        
        for i, result in enumerate(results, 1):
            print(f"\nüìÑ RESULTADO {i}:")
            print(f"   üéØ Similaridade: {result['similarity']:.3f}")
            
            # üìç INFORMA√á√ïES CONTEXTUAIS
            if 'document_title' in result:
                print(f"   üìö Documento: {result['document_title']}")
            if 'chunk_position' in result:
                print(f"   üìç Posi√ß√£o: Chunk {result['chunk_position']}")
            
            # üìù PREVIEW DO CONTE√öDO
            preview_text = result['text'][:100].replace('\n', ' ')
            print(f"   üìù Texto: {preview_text}...")
            
            # üè∑Ô∏è METADADOS ADICIONAIS
            metadata = result['metadata']
            if 'autor' in metadata:
                print(f"   üë§ Autor: {metadata['autor']}")
            if 'categoria' in metadata:
                print(f"   üè∑Ô∏è Categoria: {metadata['categoria']}")

# üéì EXECUTAR DEMONSTRA√á√ÉO
exemplo_documento_longo()
```

### üìä **An√°lise Educacional dos Resultados**

```python
def analisar_resultados_educacional():
    """An√°lise detalhada para fins educacionais"""
    
    print("\n" + "="*60)
    print("üìä AN√ÅLISE EDUCACIONAL DOS RESULTADOS")
    print("="*60)
    
    print("""
    üéØ O QUE OBSERVAR NOS RESULTADOS:
    
    1. üìà SCORES DE SIMILARIDADE:
       ‚Ä¢ 0.8-1.0: Correspond√™ncia muito alta (quase exata)
       ‚Ä¢ 0.6-0.8: Correspond√™ncia boa (semanticamente relacionada)
       ‚Ä¢ 0.4-0.6: Correspond√™ncia moderada (pode ser relevante)
       ‚Ä¢ 0.0-0.4: Correspond√™ncia baixa (pouco relevante)
    
    2. üé™ CONTEXTO PRESERVADO:
       ‚Ä¢ T√≠tulo do documento original mantido
       ‚Ä¢ Posi√ß√£o do chunk no documento (ex: "2/4" = chunk 2 de 4)
       ‚Ä¢ Metadados customizados preservados
    
    3. üîç QUALIDADE DA BUSCA:
       ‚Ä¢ "redes neurais" ‚Üí deve encontrar par√°grafo sobre deep learning
       ‚Ä¢ "algoritmos" ‚Üí deve encontrar se√ß√£o sobre machine learning
       ‚Ä¢ "embeddings" ‚Üí deve encontrar par√°grafo espec√≠fico sobre embeddings
    
    4. ‚ö° VANTAGENS DO CHUNKING:
       ‚Ä¢ Respostas mais precisas (chunks focados vs documento inteiro)
       ‚Ä¢ Melhor performance (embeddings menores)
       ‚Ä¢ Contexto preservado (sabemos de onde veio cada resultado)
    """)

analisar_resultados_educacional()
```

### üéì **Pontos-Chave**

1. **üß© Chunking Inteligente**: Dividir por senten√ßas preserva significado
2. **üè∑Ô∏è Metadados Ricos**: Rastreabilidade √© fundamental em sistemas reais
3. **üîç Busca Contextualizada**: N√£o basta encontrar, precisa saber de onde veio
4. **‚öñÔ∏è Trade-offs**: Chunks menores = mais precis√£o, mas mais complexidade
5. **üöÄ Escalabilidade**: Sistema funciona com documentos de qualquer tamanho

## 5.3 M√©tricas e Avalia√ß√£o

### üéØ **Por que Avaliar Sistemas de Embeddings?**

A avalia√ß√£o √© fundamental para:
- **üìä Medir performance**: Quantificar qu√£o bem o sistema funciona
- **üîç Detectar problemas**: Identificar falhas na recupera√ß√£o de documentos
- **‚öñÔ∏è Comparar modelos**: Escolher a melhor abordagem para seu caso
- **üéØ Otimizar par√¢metros**: Ajustar configura√ß√µes do sistema
- **üìà Monitorar qualidade**: Acompanhar performance ao longo do tempo

```python
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, roc_curve, auc
from sklearn.metrics.pairwise import cosine_similarity
import seaborn as sns
import numpy as np
from typing import List, Tuple, Dict

class EmbeddingEvaluator:
    """
    üéì CLASSE EDUCACIONAL: Avalia√ß√£o de Sistemas de Embeddings
    
    Esta classe implementa m√©tricas essenciais para avaliar:
    - Qualidade da busca sem√¢ntica
    - Distribui√ß√£o de similaridades
    - Estrutura do espa√ßo de embeddings
    """
    
    def __init__(self, search_system):
        """
        Inicializar avaliador
        
        Args:
            search_system: Sistema de busca com embeddings (EmbeddingSearchSystem)
        """
        self.search_system = search_system
    
    def evaluate_search_quality(self, test_queries: List[Tuple[str, List[str]]]) -> Dict:
        """
        üéØ M√âTODO PRINCIPAL: Avaliar qualidade da busca usando queries de teste
        
        üìö CONCEITOS-CHAVE:
        - Precision@K: Propor√ß√£o de documentos relevantes nos top-K resultados
        - Recall@K: Propor√ß√£o dos documentos relevantes que foram encontrados
        - MRR: Mean Reciprocal Rank - posi√ß√£o m√©dia do primeiro resultado relevante
        
        Args:
            test_queries: Lista de tuplas (query, [doc_ids_relevantes])
            
        Returns:
            Dict com m√©tricas calculadas
            
        üí° EXEMPLO DE USO:
        test_queries = [
            ("machine learning", ["doc1", "doc3", "doc7"]),
            ("python programming", ["doc2", "doc5"])
        ]
        """
        metrics = {
            'precision_at_k': [],  # Lista de tuplas (k, precision)
            'recall_at_k': [],     # Lista de tuplas (k, recall)
            'mrr': []              # Lista de valores MRR por query
        }
        
        print("üîç AVALIANDO QUALIDADE DA BUSCA")
        print("=" * 50)
        
        for i, (query, relevant_docs) in enumerate(test_queries):
            print(f"\nQuery {i+1}: '{query}'")
            print(f"Documentos relevantes esperados: {len(relevant_docs)}")
            
            # Buscar documentos
            results = self.search_system.search(query, top_k=10)
            result_ids = [doc_id for doc_id, _, _ in results]
            
            print(f"Documentos retornados: {len(result_ids)}")
            
            # üìä PRECISION@K e RECALL@K
            for k in [1, 3, 5, 10]:
                top_k_results = result_ids[:k]
                relevant_found = len(set(top_k_results) & set(relevant_docs))
                
                # Precision@K = Relevantes encontrados / K
                precision = relevant_found / k if k > 0 else 0
                
                # Recall@K = Relevantes encontrados / Total de relevantes
                recall = relevant_found / len(relevant_docs) if len(relevant_docs) > 0 else 0
                
                metrics['precision_at_k'].append((k, precision))
                metrics['recall_at_k'].append((k, recall))
                
                print(f"  P@{k}: {precision:.3f} | R@{k}: {recall:.3f}")
            
            # üéØ MEAN RECIPROCAL RANK (MRR)
            # Encontra a posi√ß√£o do primeiro documento relevante
            for j, doc_id in enumerate(result_ids):
                if doc_id in relevant_docs:
                    mrr_score = 1 / (j + 1)  # Posi√ß√£o 1 = 1.0, Posi√ß√£o 2 = 0.5, etc.
                    metrics['mrr'].append(mrr_score)
                    print(f"  MRR: {mrr_score:.3f} (primeiro relevante na posi√ß√£o {j+1})")
                    break
            else:
                # Nenhum documento relevante encontrado
                metrics['mrr'].append(0)
                print(f"  MRR: 0.000 (nenhum documento relevante encontrado)")
        
        # üìà RESUMO DAS M√âTRICAS
        self._print_metrics_summary(metrics)
        return metrics
    
    def _print_metrics_summary(self, metrics: Dict):
        """Imprimir resumo das m√©tricas calculadas"""
        print("\n" + "="*50)
        print("üìä RESUMO DAS M√âTRICAS")
        print("="*50)
        
        # Agrupar m√©tricas por K
        precision_by_k = {}
        recall_by_k = {}
        
        for k, precision in metrics['precision_at_k']:
            if k not in precision_by_k:
                precision_by_k[k] = []
            precision_by_k[k].append(precision)
        
        for k, recall in metrics['recall_at_k']:
            if k not in recall_by_k:
                recall_by_k[k] = []
            recall_by_k[k].append(recall)
        
        # Calcular m√©dias
        print("Precision@K (m√©dia):")
        for k in sorted(precision_by_k.keys()):
            avg_precision = np.mean(precision_by_k[k])
            print(f"  P@{k}: {avg_precision:.3f}")
        
        print("\nRecall@K (m√©dia):")
        for k in sorted(recall_by_k.keys()):
            avg_recall = np.mean(recall_by_k[k])
            print(f"  R@{k}: {avg_recall:.3f}")
        
        avg_mrr = np.mean(metrics['mrr'])
        print(f"\nMRR m√©dio: {avg_mrr:.3f}")
        
        # Interpreta√ß√£o educacional
        print("\nüéì INTERPRETA√á√ÉO:")
        if avg_mrr > 0.7:
            print("‚úÖ Excelente: Sistema encontra documentos relevantes nas primeiras posi√ß√µes")
        elif avg_mrr > 0.5:
            print("üü° Bom: Sistema tem performance razo√°vel")
        else:
            print("‚ùå Ruim: Sistema precisa de melhorias")
    
    def plot_similarity_distribution(self, query: str, num_samples: int = 100):
        """
        üìä VISUALIZA√á√ÉO: Distribui√ß√£o de similaridades
        
        üéØ OBJETIVO: Entender como as similaridades se distribuem
        
        üìö O QUE ANALISAR:
        - Distribui√ß√£o normal: Boa diversidade de documentos
        - Pico √† esquerda: Muitos documentos irrelevantes
        - Pico √† direita: Documentos muito similares (poss√≠vel duplica√ß√£o)
        - Distribui√ß√£o uniforme: Falta de discrimina√ß√£o sem√¢ntica
        """
        print(f"üìä ANALISANDO DISTRIBUI√á√ÉO DE SIMILARIDADES")
        print(f"Query: '{query}'")
        print("-" * 40)
        
        results = self.search_system.search(query, top_k=num_samples)
        similarities = [sim for _, sim, _ in results]
        
        if not similarities:
            print("‚ùå Nenhum resultado encontrado!")
            return
        
        # Estat√≠sticas descritivas
        print(f"N√∫mero de documentos analisados: {len(similarities)}")
        print(f"Similaridade m√©dia: {np.mean(similarities):.3f}")
        print(f"Similaridade mediana: {np.median(similarities):.3f}")
        print(f"Desvio padr√£o: {np.std(similarities):.3f}")
        print(f"Min: {np.min(similarities):.3f} | Max: {np.max(similarities):.3f}")
        
        # Determinar n√∫mero apropriado de bins
        n_bins = min(20, max(3, len(set(similarities))))
        
        # Criar visualiza√ß√£o
        plt.figure(figsize=(12, 8))
        
        # Histograma principal
        plt.subplot(2, 2, 1)
        n, bins, patches = plt.hist(similarities, bins=n_bins, alpha=0.7, 
                                   edgecolor='black', color='skyblue')
        plt.title(f'Distribui√ß√£o de Similaridades\nQuery: "{query}"')
        plt.xlabel('Similaridade (Cosseno)')
        plt.ylabel('Frequ√™ncia')
        plt.grid(True, alpha=0.3)
        
        # Adicionar linha da m√©dia
        plt.axvline(np.mean(similarities), color='red', linestyle='--', 
                   label=f'M√©dia: {np.mean(similarities):.3f}')
        plt.legend()
        
        # Box plot
        plt.subplot(2, 2, 2)
        plt.boxplot(similarities, vert=True)
        plt.title('Box Plot das Similaridades')
        plt.ylabel('Similaridade')
        plt.grid(True, alpha=0.3)
        
        # Distribui√ß√£o cumulativa
        plt.subplot(2, 2, 3)
        sorted_sims = np.sort(similarities)
        cumulative = np.arange(1, len(sorted_sims) + 1) / len(sorted_sims)
        plt.plot(sorted_sims, cumulative, marker='o', markersize=3)
        plt.title('Distribui√ß√£o Cumulativa')
        plt.xlabel('Similaridade')
        plt.ylabel('Propor√ß√£o Acumulada')
        plt.grid(True, alpha=0.3)
        
        # Top-K similarities
        plt.subplot(2, 2, 4)
        top_k = min(20, len(similarities))
        plt.plot(range(1, top_k + 1), similarities[:top_k], 
                marker='o', markersize=4, color='orange')
        plt.title(f'Top-{top_k} Similaridades')
        plt.xlabel('Ranking')
        plt.ylabel('Similaridade')
        plt.grid(True, alpha=0.3)
        
        plt.tight_layout()
        plt.show()
        
        # Interpreta√ß√£o educacional
        print("\nüéì INTERPRETA√á√ÉO DA DISTRIBUI√á√ÉO:")
        if np.std(similarities) < 0.1:
            print("‚ö†Ô∏è  Baixa variabilidade - documentos muito similares entre si")
        elif np.mean(similarities) < 0.3:
            print("‚ö†Ô∏è  Similaridades baixas - poss√≠vel problema de relev√¢ncia")
        elif np.mean(similarities) > 0.8:
            print("‚ö†Ô∏è  Similaridades muito altas - poss√≠vel overfitting ou duplica√ß√£o")
        else:
            print("‚úÖ Distribui√ß√£o saud√°vel de similaridades")
    
    def analyze_embedding_space(self):
        """
        üîç AN√ÅLISE AVAN√áADA: Estrutura do espa√ßo de embeddings
        
        üéØ OBJETIVO: Entender as propriedades geom√©tricas do espa√ßo vetorial
        
        üìö O QUE ANALISAMOS:
        - Dimensionalidade e densidade
        - Distribui√ß√£o de normas (magnitudes dos vetores)
        - Matriz de similaridade entre todos os documentos
        - Clusters e padr√µes estruturais
        """
        print("üîç AN√ÅLISE DO ESPA√áO DE EMBEDDINGS")
        print("=" * 50)
        
        if len(self.search_system.embeddings) < 2:
            print("‚ùå N√£o h√° embeddings suficientes para an√°lise (m√≠nimo: 2)")
            return
        
        # Converter embeddings para matriz numpy
        embeddings_matrix = np.array(list(self.search_system.embeddings.values()))
        doc_ids = list(self.search_system.embeddings.keys())
        
        # üìä ESTAT√çSTICAS B√ÅSICAS
        print("üìä ESTAT√çSTICAS B√ÅSICAS:")
        print(f"  N√∫mero de documentos: {len(embeddings_matrix)}")
        print(f"  Dimensionalidade: {embeddings_matrix.shape[1]}")
        
        # An√°lise de normas (magnitudes dos vetores)
        norms = np.linalg.norm(embeddings_matrix, axis=1)
        print(f"  Norma m√©dia: {np.mean(norms):.3f}")
        print(f"  Desvio padr√£o da norma: {np.std(norms):.3f}")
        print(f"  Norma m√≠n/m√°x: {np.min(norms):.3f} / {np.max(norms):.3f}")
        
        # An√°lise de distribui√ß√£o por dimens√£o
        print(f"  M√©dia por dimens√£o: {np.mean(np.mean(embeddings_matrix, axis=0)):.3f}")
        print(f"  Desvio padr√£o por dimens√£o: {np.mean(np.std(embeddings_matrix, axis=0)):.3f}")
        
        # üéØ MATRIZ DE SIMILARIDADE
        print("\nüéØ CALCULANDO MATRIZ DE SIMILARIDADE...")
        similarity_matrix = cosine_similarity(embeddings_matrix)
        
        # Estat√≠sticas da matriz de similaridade
        # Remover diagonal (similaridade consigo mesmo = 1.0)
        off_diagonal = similarity_matrix[np.triu_indices_from(similarity_matrix, k=1)]
        
        print(f"  Similaridade m√©dia entre documentos: {np.mean(off_diagonal):.3f}")
        print(f"  Desvio padr√£o das similaridades: {np.std(off_diagonal):.3f}")
        print(f"  Similaridade m√≠n/m√°x: {np.min(off_diagonal):.3f} / {np.max(off_diagonal):.3f}")
        
        # üìä VISUALIZA√á√ïES
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # 1. Heatmap da matriz de similaridade
        ax1 = axes[0, 0]
        im = ax1.imshow(similarity_matrix, cmap='coolwarm', vmin=-1, vmax=1)
        ax1.set_title('Matriz de Similaridade entre Documentos')
        ax1.set_xlabel('Documento ID')
        ax1.set_ylabel('Documento ID')
        plt.colorbar(im, ax=ax1)
        
        # 2. Distribui√ß√£o das similaridades
        ax2 = axes[0, 1]
        # Determinar n√∫mero apropriado de bins para similaridades
        n_bins_sim = min(30, max(5, len(set(off_diagonal))))
        ax2.hist(off_diagonal, bins=n_bins_sim, alpha=0.7, edgecolor='black', color='lightgreen')
        ax2.axvline(np.mean(off_diagonal), color='red', linestyle='--', 
                   label=f'M√©dia: {np.mean(off_diagonal):.3f}')
        ax2.set_title('Distribui√ß√£o das Similaridades')
        ax2.set_xlabel('Similaridade Cosseno')
        ax2.set_ylabel('Frequ√™ncia')
        ax2.legend()
        ax2.grid(True, alpha=0.3)
        
        # 3. Distribui√ß√£o das normas
        ax3 = axes[1, 0]
        # Determinar n√∫mero apropriado de bins para normas
        unique_norms = np.unique(norms)
        if len(unique_norms) < 3:
            # Se h√° poucas normas √∫nicas, usar bar plot
            ax3.bar(range(len(unique_norms)), 
                   [np.sum(norms == norm) for norm in unique_norms],
                   alpha=0.7, color='orange')
            ax3.set_xticks(range(len(unique_norms)))
            ax3.set_xticklabels([f'{norm:.3f}' for norm in unique_norms])
            ax3.set_title('Distribui√ß√£o das Normas dos Vetores')
            ax3.set_xlabel('Norma (Magnitude)')
            ax3.set_ylabel('Frequ√™ncia')
        else:
            n_bins_norms = min(20, max(3, len(unique_norms)))
            ax3.hist(norms, bins=n_bins_norms, alpha=0.7, edgecolor='black', color='orange')
            ax3.axvline(np.mean(norms), color='red', linestyle='--', 
                       label=f'M√©dia: {np.mean(norms):.3f}')
            ax3.set_title('Distribui√ß√£o das Normas dos Vetores')
            ax3.set_xlabel('Norma (Magnitude)')
            ax3.set_ylabel('Frequ√™ncia')
            ax3.legend()
        ax3.grid(True, alpha=0.3)
        
        # 4. Heatmap de correla√ß√£o entre dimens√µes (amostra)
        ax4 = axes[1, 1]
        # Usar apenas primeiras 20 dimens√µes para visualiza√ß√£o
        sample_dims = min(20, embeddings_matrix.shape[1])
        correlation_matrix = np.corrcoef(embeddings_matrix[:, :sample_dims].T)
        im4 = ax4.imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)
        ax4.set_title(f'Correla√ß√£o entre Dimens√µes\n(Primeiras {sample_dims} dimens√µes)')
        ax4.set_xlabel('Dimens√£o')
        ax4.set_ylabel('Dimens√£o')
        plt.colorbar(im4, ax=ax4)
        
        plt.tight_layout()
        plt.show()
        
        # üéì INTERPRETA√á√ÉO EDUCACIONAL
        print("\nüéì INTERPRETA√á√ÉO DOS RESULTADOS:")
        print("-" * 40)
        
        if np.std(norms) < 0.1:
            print("‚úÖ Normas consistentes - embeddings bem normalizados")
        else:
            print("‚ö†Ô∏è  Normas vari√°veis - considere normaliza√ß√£o L2")
        
        if np.mean(off_diagonal) > 0.7:
            print("‚ö†Ô∏è  Similaridades muito altas - poss√≠vel falta de diversidade")
        elif np.mean(off_diagonal) < 0.1:
            print("‚ö†Ô∏è  Similaridades muito baixas - documentos muito diferentes")
        else:
            print("‚úÖ Distribui√ß√£o saud√°vel de similaridades")
        
        if np.std(off_diagonal) < 0.1:
            print("‚ö†Ô∏è  Pouca variabilidade - embeddings podem estar saturados")
        else:
            print("‚úÖ Boa variabilidade nas similaridades")
        
        # Detectar poss√≠veis clusters
        high_similarity_pairs = np.sum(off_diagonal > 0.8)
        total_pairs = len(off_diagonal)
        cluster_ratio = high_similarity_pairs / total_pairs
        
        print(f"\nüîç DETEC√á√ÉO DE CLUSTERS:")
        print(f"  Pares com alta similaridade (>0.8): {high_similarity_pairs}/{total_pairs} ({cluster_ratio:.1%})")
        
        if cluster_ratio > 0.3:
            print("üéØ Poss√≠veis clusters detectados - documentos agrupados por temas")
        else:
            print("üìä Distribui√ß√£o uniforme - boa diversidade tem√°tica")

# üöÄ EXEMPLO DE USO EDUCACIONAL
def exemplo_avaliacao_completa():
    """Demonstra√ß√£o completa do sistema de avalia√ß√£o"""
    print("üéì DEMONSTRA√á√ÉO: SISTEMA DE AVALIA√á√ÉO DE EMBEDDINGS")
    print("=" * 60)
    
    # Simular sistema de busca com documentos de exemplo
    from sentence_transformers import SentenceTransformer
    import uuid
    
    class EmbeddingSearchSystem:
        def __init__(self):
            self.model = SentenceTransformer('all-MiniLM-L6-v2')
            self.documents = {}
            self.embeddings = {}
            self.document_ids = []
        
        def add_document(self, text, metadata=None):
            doc_id = str(uuid.uuid4())
            self.documents[doc_id] = {'text': text, 'metadata': metadata or {}}
            embedding = self.model.encode([text])[0]
            self.embeddings[doc_id] = embedding
            self.document_ids.append(doc_id)
            return doc_id
        
        def search(self, query, top_k=5):
            if not self.documents:
                return []
            
            query_embedding = self.model.encode([query])[0]
            similarities = []
            
            for doc_id in self.document_ids:
                doc_embedding = self.embeddings[doc_id]
                similarity = cosine_similarity([query_embedding], [doc_embedding])[0][0]
                similarities.append((doc_id, similarity, self.documents[doc_id]['text']))
            
            similarities.sort(key=lambda x: x[1], reverse=True)
            return similarities[:top_k]
    
    search_system = EmbeddingSearchSystem()
    
    # Adicionar documentos de exemplo
    documentos_exemplo = [
        "Python √© uma linguagem de programa√ß√£o vers√°til",
        "Machine learning utiliza algoritmos para encontrar padr√µes",
        "Deep learning √© um subcampo do machine learning",
        "Redes neurais artificiais imitam o c√©rebro humano",
        "Processamento de linguagem natural permite compreender texto"
    ]
    
    doc_ids = []
    for doc in documentos_exemplo:
        doc_id = search_system.add_document(doc)
        doc_ids.append(doc_id)
    
    # Criar avaliador
    evaluator = EmbeddingEvaluator(search_system)
    
    # Definir queries de teste
    test_queries = [
        ("aprendizado de m√°quina", [doc_ids[1], doc_ids[2]]),  # ML e DL
        ("linguagem de programa√ß√£o", [doc_ids[0]]),             # Python
        ("intelig√™ncia artificial", [doc_ids[1], doc_ids[2], doc_ids[3]])  # ML, DL, NN
    ]
    
    # 1. Avaliar qualidade da busca
    print("\n1Ô∏è‚É£ AVALIA√á√ÉO DA QUALIDADE DA BUSCA")
    metrics = evaluator.evaluate_search_quality(test_queries)
    
    # 2. Analisar distribui√ß√£o de similaridades
    print("\n2Ô∏è‚É£ AN√ÅLISE DE DISTRIBUI√á√ÉO DE SIMILARIDADES")
    evaluator.plot_similarity_distribution("machine learning")
    
    # 3. Analisar espa√ßo de embeddings
    print("\n3Ô∏è‚É£ AN√ÅLISE DO ESPA√áO DE EMBEDDINGS")
    evaluator.analyze_embedding_space()

# Executar exemplo
exemplo_avaliacao_completa()
```

### üéØ **M√©tricas-Chave Explicadas**

#### üìä **Precision@K**
- **F√≥rmula**: `Precision@K = Documentos Relevantes nos Top-K / K`
- **Interpreta√ß√£o**: "Dos K documentos que retornei, quantos s√£o realmente relevantes?"
- **Exemplo**: Se busco por "Python" e nos top-3 resultados, 2 s√£o relevantes ‚Üí P@3 = 2/3 = 0.67

#### üìà **Recall@K**
- **F√≥rmula**: `Recall@K = Documentos Relevantes Encontrados / Total de Relevantes`
- **Interpreta√ß√£o**: "Dos documentos relevantes que existem, quantos consegui encontrar?"
- **Exemplo**: Se existem 5 docs relevantes e encontrei 3 nos top-10 ‚Üí R@10 = 3/5 = 0.60

#### üéØ **Mean Reciprocal Rank (MRR)**
- **F√≥rmula**: `MRR = 1/posi√ß√£o_primeiro_relevante`
- **Interpreta√ß√£o**: "Qu√£o r√°pido encontro o primeiro resultado relevante?"
- **Exemplo**: Primeiro relevante na posi√ß√£o 2 ‚Üí MRR = 1/2 = 0.50

### üí° **Dicas Educacionais**

1. **üéØ Precision vs Recall Trade-off**: Alta precision pode significar baixo recall e vice-versa
2. **üìä MRR √© crucial**: Usu√°rios geralmente olham apenas os primeiros resultados
3. **üîç Distribui√ß√£o de similaridades**: Revela muito sobre a qualidade dos embeddings
4. **‚öñÔ∏è Balance √© importante**: Nem muito similares (duplica√ß√£o) nem muito diferentes (irrelev√¢ncia)

```python
import matplotlib.pyplot as plt
from sklearn.metrics import precision_recall_curve, roc_curve, auc
import seaborn as sns

class EmbeddingEvaluator:
    def __init__(self, search_system: EmbeddingSearchSystem):
        self.search_system = search_system
    
    def evaluate_search_quality(self, test_queries: List[Tuple[str, List[str]]]) -> Dict:
        """Avaliar qualidade da busca usando queries de teste"""
        metrics = {
            'precision_at_k': [],
            'recall_at_k': [],
            'mrr': []  # Mean Reciprocal Rank
        }
        
        for query, relevant_docs in test_queries:
            results = self.search_system.search(query, top_k=10)
            result_ids = [doc_id for doc_id, _, _ in results]
            
            # Precision@K e Recall@K
            for k in [1, 3, 5, 10]:
                top_k_results = result_ids[:k]
                relevant_found = len(set(top_k_results) & set(relevant_docs))
                
                precision = relevant_found / k if k > 0 else 0
                recall = relevant_found / len(relevant_docs) if len(relevant_docs) > 0 else 0
                
                metrics['precision_at_k'].append((k, precision))
                metrics['recall_at_k'].append((k, recall))
            
            # Mean Reciprocal Rank
            for i, doc_id in enumerate(result_ids):
                if doc_id in relevant_docs:
                    metrics['mrr'].append(1 / (i + 1))
                    break
            else:
                metrics['mrr'].append(0)
        
        return metrics
    
    def plot_similarity_distribution(self, query: str, num_samples: int = 100):
        """Plotar distribui√ß√£o de similaridades"""
        results = self.search_system.search(query, top_k=num_samples)
        similarities = [sim for _, sim, _ in results]
        
        plt.figure(figsize=(10, 6))
        plt.hist(similarities, bins=20, alpha=0.7, edgecolor='black')
        plt.title(f'Distribui√ß√£o de Similaridades para: "{query}"')
        plt.xlabel('Similaridade (Cosseno)')
        plt.ylabel('Frequ√™ncia')
        plt.grid(True, alpha=0.3)
        plt.show()
    
    def analyze_embedding_space(self):
        """Analisar o espa√ßo de embeddings"""
        if len(self.search_system.embeddings) < 2:
            print("N√£o h√° embeddings suficientes para an√°lise")
            return
        
        embeddings_matrix = np.array(list(self.search_system.embeddings.values()))
        
        # Estat√≠sticas b√°sicas
        print("An√°lise do Espa√ßo de Embeddings:")
        print(f"N√∫mero de documentos: {len(embeddings_matrix)}")
        print(f"Dimensionalidade: {embeddings_matrix.shape[1]}")
        print(f"Norma m√©dia: {np.mean(np.linalg.norm(embeddings_matrix, axis=1)):.3f}")
        print(f"Desvio padr√£o da norma: {np.std(np.linalg.norm(embeddings_matrix, axis=1)):.3f}")
        
        # Matriz de similaridade
        similarity_matrix = cosine_similarity(embeddings_matrix)
        
        plt.figure(figsize=(10, 8))
        sns.heatmap(similarity_matrix, cmap='coolwarm', center=0)
        plt.title('Matriz de Similaridade entre Documentos')
        plt.show()
```