## 3. NoÃ§Ã£o de Chunking (DivisÃ£o de Documentos Longos)

### ğŸ¯ **Por que Chunking Ã© Fundamental?**

O **chunking** Ã© uma tÃ©cnica essencial no processamento de documentos longos, especialmente quando trabalhamos com:

- **ğŸ¤– Modelos de linguagem**: Que tÃªm limites de tokens de entrada (ex: GPT-3.5 = 4K tokens)
- **ğŸ” Sistemas de busca semÃ¢ntica**: Chunks menores oferecem maior precisÃ£o na recuperaÃ§Ã£o
- **ğŸ’¾ Armazenamento eficiente**: Embeddings de chunks sÃ£o mais gerenciÃ¡veis que documentos completos
- **âš¡ Performance**: Processamento paralelo de chunks independentes

### ğŸ§  **Conceitos-Chave**

- **Chunk Size**: Tamanho ideal do fragmento (geralmente 256-1024 tokens)
- **Overlap**: SobreposiÃ§Ã£o entre chunks para preservar contexto
- **Boundary Preservation**: Respeitar limites naturais do texto (sentenÃ§as, parÃ¡grafos)

### 3.1 EstratÃ©gias de Chunking

```python
import re
from typing import List, Tuple

class DocumentChunker:
    def __init__(self, chunk_size: int = 512, overlap: int = 50):
        """
        Inicializa o chunker com parÃ¢metros configurÃ¡veis
        
        Args:
            chunk_size: Tamanho mÃ¡ximo do chunk em caracteres
            overlap: NÃºmero de caracteres de sobreposiÃ§Ã£o entre chunks
        
        ğŸ’¡ Dica: chunk_size tÃ­pico = 256-1024, overlap = 10-20% do chunk_size
        """
        self.chunk_size = chunk_size
        self.overlap = overlap
    
    def chunk_by_sentences(self, text: str) -> List[str]:
        """
        ğŸ“ ESTRATÃ‰GIA 1: DivisÃ£o por SentenÃ§as
        
        âœ… Vantagens:
        - Preserva integridade semÃ¢ntica das frases
        - MantÃ©m contexto completo dentro de cada chunk
        - Ideal para textos narrativos e artigos
        
        âŒ Desvantagens:
        - Chunks podem ter tamanhos muito variados
        - SentenÃ§as muito longas podem exceder o limite
        
        ğŸ¯ Melhor uso: Documentos com sentenÃ§as bem estruturadas
        """
        sentences = re.split(r'[.!?]+', text)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            sentence = sentence.strip()
            if not sentence:  # Pular sentenÃ§as vazias
                continue
                
            # Verificar se adicionar a sentenÃ§a excede o limite
            potential_chunk = current_chunk + sentence + ". "
            
            if len(potential_chunk) < self.chunk_size:
                current_chunk = potential_chunk
            else:
                # Salvar chunk atual se nÃ£o estiver vazio
                if current_chunk:
                    chunks.append(current_chunk.strip())
                # Iniciar novo chunk com a sentenÃ§a atual
                current_chunk = sentence + ". "
        
        # Adicionar Ãºltimo chunk se houver conteÃºdo
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def chunk_by_tokens(self, text: str) -> List[str]:
        """
        ğŸ”¤ ESTRATÃ‰GIA 2: DivisÃ£o por Tokens (Palavras) com SobreposiÃ§Ã£o
        
        âœ… Vantagens:
        - Chunks de tamanho consistente
        - SobreposiÃ§Ã£o preserva contexto entre chunks
        - Controle preciso sobre o tamanho
        
        âŒ Desvantagens:
        - Pode quebrar sentenÃ§as no meio
        - SobreposiÃ§Ã£o pode causar redundÃ¢ncia
        
        ğŸ¯ Melhor uso: Quando precisÃ£o de tamanho Ã© crucial
        """
        words = text.split()
        chunks = []
        
        # Iterar com step = chunk_size - overlap para criar sobreposiÃ§Ã£o
        for i in range(0, len(words), self.chunk_size - self.overlap):
            chunk_words = words[i:i + self.chunk_size]
            chunk_text = " ".join(chunk_words)
            chunks.append(chunk_text)
            
            # Parar se nÃ£o hÃ¡ mais palavras suficientes
            if i + self.chunk_size >= len(words):
                break
        
        return chunks
    
    def chunk_by_paragraphs(self, text: str) -> List[str]:
        """
        ğŸ“„ ESTRATÃ‰GIA 3: DivisÃ£o por ParÃ¡grafos
        
        âœ… Vantagens:
        - Preserva estrutura lÃ³gica do documento
        - MantÃ©m tÃ³picos relacionados juntos
        - Respeita formataÃ§Ã£o original
        
        âŒ Desvantagens:
        - ParÃ¡grafos podem ser muito longos ou curtos
        - Dependente da qualidade da formataÃ§Ã£o
        
        ğŸ¯ Melhor uso: Documentos bem estruturados (artigos, papers)
        """
        paragraphs = text.split('\n\n')
        chunks = []
        current_chunk = ""
        
        for paragraph in paragraphs:
            paragraph = paragraph.strip()
            if not paragraph:
                continue
            
            potential_chunk = current_chunk + paragraph + "\n\n"
            
            if len(potential_chunk) < self.chunk_size:
                current_chunk = potential_chunk
            else:
                # Salvar chunk atual se nÃ£o estiver vazio
                if current_chunk:
                    chunks.append(current_chunk.strip())
                # Verificar se parÃ¡grafo sozinho excede limite
                if len(paragraph) > self.chunk_size:
                    # Dividir parÃ¡grafo longo em sentenÃ§as
                    sentences = re.split(r'[.!?]+', paragraph)
                    temp_chunk = ""
                    for sentence in sentences:
                        if sentence.strip():
                            if len(temp_chunk + sentence) < self.chunk_size:
                                temp_chunk += sentence.strip() + ". "
                            else:
                                if temp_chunk:
                                    chunks.append(temp_chunk.strip())
                                temp_chunk = sentence.strip() + ". "
                    if temp_chunk:
                        current_chunk = temp_chunk
                else:
                    current_chunk = paragraph + "\n\n"
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks

    def analyze_chunks(self, chunks: List[str]) -> None:
        """
        ğŸ“Š MÃ©todo auxiliar para analisar qualidade dos chunks
        """
        if not chunks:
            print("âŒ Nenhum chunk foi gerado!")
            return
        
        sizes = [len(chunk) for chunk in chunks]
        word_counts = [len(chunk.split()) for chunk in chunks]
        
        print(f"ğŸ“ˆ ANÃLISE DOS CHUNKS:")
        print(f"   Total de chunks: {len(chunks)}")
        print(f"   Tamanho mÃ©dio: {sum(sizes)/len(sizes):.1f} caracteres")
        print(f"   Tamanho min/max: {min(sizes)}/{max(sizes)} caracteres")
        print(f"   Palavras mÃ©dias por chunk: {sum(word_counts)/len(word_counts):.1f}")
        print(f"   ConfiguraÃ§Ã£o: chunk_size={self.chunk_size}, overlap={self.overlap}")

# ğŸš€ EXEMPLO PRÃTICO EXPANDIDO
def exemplo_chunking_completo():
    """DemonstraÃ§Ã£o completa das estratÃ©gias de chunking"""
    
    texto_exemplo = """
A inteligÃªncia artificial Ã© uma Ã¡rea da ciÃªncia da computaÃ§Ã£o que se concentra 
na criaÃ§Ã£o de sistemas capazes de realizar tarefas que normalmente requerem 
inteligÃªncia humana. Isso inclui aprendizado, raciocÃ­nio, percepÃ§Ã£o e 
processamento de linguagem natural.

Os embeddings sÃ£o uma tÃ©cnica fundamental em IA que converte dados categÃ³ricos 
ou textuais em representaÃ§Ãµes vetoriais densas. Essas representaÃ§Ãµes capturam 
relaÃ§Ãµes semÃ¢nticas entre os dados de forma que itens similares tenham 
representaÃ§Ãµes prÃ³ximas no espaÃ§o vetorial.

O processamento de linguagem natural (NLP) utiliza essas tÃ©cnicas para 
compreender e gerar texto humano. AplicaÃ§Ãµes incluem traduÃ§Ã£o automÃ¡tica, 
anÃ¡lise de sentimentos, chatbots e sistemas de recomendaÃ§Ã£o baseados em conteÃºdo.
"""
    
    print("ğŸ“ DEMONSTRAÃ‡ÃƒO: ESTRATÃ‰GIAS DE CHUNKING")
    print("=" * 60)
    
    # Configurar chunker
    chunker = DocumentChunker(chunk_size=200, overlap=30)
    
    # Testar cada estratÃ©gia
    strategies = [
        ("SentenÃ§as", chunker.chunk_by_sentences),
        ("Tokens", chunker.chunk_by_tokens),
        ("ParÃ¡grafos", chunker.chunk_by_paragraphs)
    ]
    
    for strategy_name, strategy_method in strategies:
        print(f"\nğŸ” ESTRATÃ‰GIA: {strategy_name.upper()}")
        print("-" * 40)
        
        chunks = strategy_method(texto_exemplo)
        chunker.analyze_chunks(chunks)
        
        print(f"\nğŸ“ Primeiros 2 chunks:")
        for i, chunk in enumerate(chunks[:2]):
            print(f"   Chunk {i+1}: {chunk[:100]}...")
            
        # Demonstrar sobreposiÃ§Ã£o (apenas para tokens)
        if strategy_name == "Tokens" and len(chunks) > 1:
            overlap_demo = set(chunks[0].split()) & set(chunks[1].split())
            print(f"   ğŸ”„ Palavras em sobreposiÃ§Ã£o: {len(overlap_demo)}")

# Executar exemplo
exemplo_chunking_completo()
```

### ğŸ¯ **Escolhendo a EstratÃ©gia Ideal**

| **EstratÃ©gia** | **Melhor Para** | **Evitar Quando** |
|----------------|-----------------|-------------------|
| **SentenÃ§as** | Textos narrativos, artigos | SentenÃ§as muito longas |
| **Tokens** | Controle preciso de tamanho | Contexto semÃ¢ntico Ã© crucial |
| **ParÃ¡grafos** | Documentos estruturados | ParÃ¡grafos inconsistentes |

### ğŸ”§ **ParÃ¢metros Recomendados**

```python
# Para diferentes casos de uso:
CONFIGS = {
    'gpt-3.5': {'chunk_size': 3000, 'overlap': 300},    # ~4K tokens
    'bert': {'chunk_size': 400, 'overlap': 50},         # ~512 tokens
    'busca_semantica': {'chunk_size': 800, 'overlap': 100},
    'qa_system': {'chunk_size': 1500, 'overlap': 200}
}
```

### ğŸ’¡ **Dicas AvanÃ§adas**

1. **ğŸ“ MediÃ§Ã£o em Tokens**: Use tokenizadores reais em vez de caracteres
2. **ğŸ”„ Overlap Inteligente**: Termine chunks em pontos naturais
3. **ğŸ“Š ValidaÃ§Ã£o**: Sempre analise a qualidade dos chunks gerados
4. **âš–ï¸ Trade-offs**: Chunks menores = mais precisÃ£o, chunks maiores = mais contexto
