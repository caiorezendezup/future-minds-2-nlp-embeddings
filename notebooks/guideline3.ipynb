{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59d6e6ee",
   "metadata": {},
   "source": [
    "## 3. NoÃ§Ã£o de Chunking (DivisÃ£o de Documentos Longos)\n",
    "\n",
    "### ğŸ¯ **Por que Chunking Ã© Fundamental?**\n",
    "\n",
    "O **chunking** Ã© uma tÃ©cnica essencial no processamento de documentos longos, especialmente quando trabalhamos com:\n",
    "\n",
    "- **ğŸ¤– Modelos de linguagem**: Que tÃªm limites de tokens de entrada (ex: GPT-3.5 = 4K tokens)\n",
    "- **ğŸ” Sistemas de busca semÃ¢ntica**: Chunks menores oferecem maior precisÃ£o na recuperaÃ§Ã£o\n",
    "- **ğŸ’¾ Armazenamento eficiente**: Embeddings de chunks sÃ£o mais gerenciÃ¡veis que documentos completos\n",
    "- **âš¡ Performance**: Processamento paralelo de chunks independentes\n",
    "\n",
    "### ğŸ§  **Conceitos-Chave**\n",
    "\n",
    "- **Chunk Size**: Tamanho ideal do fragmento (geralmente 256-1024 tokens)\n",
    "- **Overlap**: SobreposiÃ§Ã£o entre chunks para preservar contexto\n",
    "- **Boundary Preservation**: Respeitar limites naturais do texto (sentenÃ§as, parÃ¡grafos)\n",
    "\n",
    "### 3.1 EstratÃ©gias de Chunking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc8dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ DEMONSTRAÃ‡ÃƒO: ESTRATÃ‰GIAS DE CHUNKING\n",
      "============================================================\n",
      "\n",
      "ğŸ” ESTRATÃ‰GIA: SENTENÃ‡AS\n",
      "----------------------------------------\n",
      "ğŸ“ˆ ANÃLISE DOS CHUNKS:\n",
      "   Total de chunks: 6\n",
      "   Tamanho mÃ©dio: 127.0 caracteres\n",
      "   Tamanho min/max: 85/177 caracteres\n",
      "   Palavras mÃ©dias por chunk: 17.2\n",
      "   ConfiguraÃ§Ã£o: chunk_size=200, overlap=30\n",
      "\n",
      "ğŸ“ Primeiros 2 chunks:\n",
      "   Chunk 1: A inteligÃªncia artificial Ã© uma Ã¡rea da ciÃªncia da computaÃ§Ã£o que se concentra \n",
      "na criaÃ§Ã£o de sistem...\n",
      "   Chunk 2: Isso inclui aprendizado, raciocÃ­nio, percepÃ§Ã£o e \n",
      "processamento de linguagem natural....\n",
      "\n",
      "ğŸ” ESTRATÃ‰GIA: TOKENS\n",
      "----------------------------------------\n",
      "ğŸ“ˆ ANÃLISE DOS CHUNKS:\n",
      "   Total de chunks: 1\n",
      "   Tamanho mÃ©dio: 759.0 caracteres\n",
      "   Tamanho min/max: 759/759 caracteres\n",
      "   Palavras mÃ©dias por chunk: 103.0\n",
      "   ConfiguraÃ§Ã£o: chunk_size=200, overlap=30\n",
      "\n",
      "ğŸ“ Primeiros 2 chunks:\n",
      "   Chunk 1: A inteligÃªncia artificial Ã© uma Ã¡rea da ciÃªncia da computaÃ§Ã£o que se concentra na criaÃ§Ã£o de sistema...\n",
      "\n",
      "ğŸ” ESTRATÃ‰GIA: PARÃGRAFOS\n",
      "----------------------------------------\n",
      "ğŸ“ˆ ANÃLISE DOS CHUNKS:\n",
      "   Total de chunks: 6\n",
      "   Tamanho mÃ©dio: 127.0 caracteres\n",
      "   Tamanho min/max: 85/177 caracteres\n",
      "   Palavras mÃ©dias por chunk: 17.2\n",
      "   ConfiguraÃ§Ã£o: chunk_size=200, overlap=30\n",
      "\n",
      "ğŸ“ Primeiros 2 chunks:\n",
      "   Chunk 1: A inteligÃªncia artificial Ã© uma Ã¡rea da ciÃªncia da computaÃ§Ã£o que se concentra \n",
      "na criaÃ§Ã£o de sistem...\n",
      "   Chunk 2: Isso inclui aprendizado, raciocÃ­nio, percepÃ§Ã£o e \n",
      "processamento de linguagem natural....\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from typing import List\n",
    "\n",
    "class DocumentChunker:\n",
    "    def __init__(self, chunk_size: int = 512, overlap: int = 50):\n",
    "        \"\"\"\n",
    "        Inicializa o chunker com parÃ¢metros configurÃ¡veis\n",
    "        \n",
    "        Args:\n",
    "            chunk_size: Tamanho mÃ¡ximo do chunk em caracteres\n",
    "            overlap: NÃºmero de caracteres de sobreposiÃ§Ã£o entre chunks\n",
    "        \n",
    "        ğŸ’¡ Dica: chunk_size tÃ­pico = 256-1024, overlap = 10-20% do chunk_size\n",
    "        \"\"\"\n",
    "        self.chunk_size = chunk_size\n",
    "        self.overlap = overlap\n",
    "    \n",
    "    def chunk_by_sentences(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        ğŸ“ ESTRATÃ‰GIA 1: DivisÃ£o por SentenÃ§as\n",
    "        \n",
    "        âœ… Vantagens:\n",
    "        - Preserva integridade semÃ¢ntica das frases\n",
    "        - MantÃ©m contexto completo dentro de cada chunk\n",
    "        - Ideal para textos narrativos e artigos\n",
    "        \n",
    "        âŒ Desvantagens:\n",
    "        - Chunks podem ter tamanhos muito variados\n",
    "        - SentenÃ§as muito longas podem exceder o limite\n",
    "        \n",
    "        ğŸ¯ Melhor uso: Documentos com sentenÃ§as bem estruturadas\n",
    "        \"\"\"\n",
    "        sentences = re.split(r'[.!?]+', text)\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for sentence in sentences:\n",
    "            sentence = sentence.strip()\n",
    "            if not sentence:  # Pular sentenÃ§as vazias\n",
    "                continue\n",
    "                \n",
    "            # Verificar se adicionar a sentenÃ§a excede o limite\n",
    "            potential_chunk = current_chunk + sentence + \". \"\n",
    "            \n",
    "            if len(potential_chunk) < self.chunk_size:\n",
    "                current_chunk = potential_chunk\n",
    "            else:\n",
    "                # Salvar chunk atual se nÃ£o estiver vazio\n",
    "                if current_chunk:\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                # Iniciar novo chunk com a sentenÃ§a atual\n",
    "                current_chunk = sentence + \". \"\n",
    "        \n",
    "        # Adicionar Ãºltimo chunk se houver conteÃºdo\n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def chunk_by_tokens(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        ğŸ”¤ ESTRATÃ‰GIA 2: DivisÃ£o por Tokens (Palavras) com SobreposiÃ§Ã£o\n",
    "        \n",
    "        âœ… Vantagens:\n",
    "        - Chunks de tamanho consistente\n",
    "        - SobreposiÃ§Ã£o preserva contexto entre chunks\n",
    "        - Controle preciso sobre o tamanho\n",
    "        \n",
    "        âŒ Desvantagens:\n",
    "        - Pode quebrar sentenÃ§as no meio\n",
    "        - SobreposiÃ§Ã£o pode causar redundÃ¢ncia\n",
    "        \n",
    "        ğŸ¯ Melhor uso: Quando precisÃ£o de tamanho Ã© crucial\n",
    "        \"\"\"\n",
    "        words = text.split()\n",
    "        chunks = []\n",
    "        \n",
    "        # Iterar com step = chunk_size - overlap para criar sobreposiÃ§Ã£o\n",
    "        for i in range(0, len(words), self.chunk_size - self.overlap):\n",
    "            chunk_words = words[i:i + self.chunk_size]\n",
    "            chunk_text = \" \".join(chunk_words)\n",
    "            chunks.append(chunk_text)\n",
    "            \n",
    "            # Parar se nÃ£o hÃ¡ mais palavras suficientes\n",
    "            if i + self.chunk_size >= len(words):\n",
    "                break\n",
    "        \n",
    "        return chunks\n",
    "    \n",
    "    def chunk_by_paragraphs(self, text: str) -> List[str]:\n",
    "        \"\"\"\n",
    "        ğŸ“„ ESTRATÃ‰GIA 3: DivisÃ£o por ParÃ¡grafos\n",
    "        \n",
    "        âœ… Vantagens:\n",
    "        - Preserva estrutura lÃ³gica do documento\n",
    "        - MantÃ©m tÃ³picos relacionados juntos\n",
    "        - Respeita formataÃ§Ã£o original\n",
    "        \n",
    "        âŒ Desvantagens:\n",
    "        - ParÃ¡grafos podem ser muito longos ou curtos\n",
    "        - Dependente da qualidade da formataÃ§Ã£o\n",
    "        \n",
    "        ğŸ¯ Melhor uso: Documentos bem estruturados (artigos, papers)\n",
    "        \"\"\"\n",
    "        paragraphs = text.split('\\n\\n')\n",
    "        chunks = []\n",
    "        current_chunk = \"\"\n",
    "        \n",
    "        for paragraph in paragraphs:\n",
    "            paragraph = paragraph.strip()\n",
    "            if not paragraph:\n",
    "                continue\n",
    "            \n",
    "            potential_chunk = current_chunk + paragraph + \"\\n\\n\"\n",
    "            \n",
    "            if len(potential_chunk) < self.chunk_size:\n",
    "                current_chunk = potential_chunk\n",
    "            else:\n",
    "                # Salvar chunk atual se nÃ£o estiver vazio\n",
    "                if current_chunk:\n",
    "                    chunks.append(current_chunk.strip())\n",
    "                # Verificar se parÃ¡grafo sozinho excede limite\n",
    "                if len(paragraph) > self.chunk_size:\n",
    "                    # Dividir parÃ¡grafo longo em sentenÃ§as\n",
    "                    sentences = re.split(r'[.!?]+', paragraph)\n",
    "                    temp_chunk = \"\"\n",
    "                    for sentence in sentences:\n",
    "                        if sentence.strip():\n",
    "                            if len(temp_chunk + sentence) < self.chunk_size:\n",
    "                                temp_chunk += sentence.strip() + \". \"\n",
    "                            else:\n",
    "                                if temp_chunk:\n",
    "                                    chunks.append(temp_chunk.strip())\n",
    "                                temp_chunk = sentence.strip() + \". \"\n",
    "                    if temp_chunk:\n",
    "                        current_chunk = temp_chunk\n",
    "                else:\n",
    "                    current_chunk = paragraph + \"\\n\\n\"\n",
    "        \n",
    "        if current_chunk:\n",
    "            chunks.append(current_chunk.strip())\n",
    "        \n",
    "        return chunks\n",
    "\n",
    "    def analyze_chunks(self, chunks: List[str]) -> None:\n",
    "        \"\"\"\n",
    "        ğŸ“Š MÃ©todo auxiliar para analisar qualidade dos chunks\n",
    "        \"\"\"\n",
    "        if not chunks:\n",
    "            print(\"âŒ Nenhum chunk foi gerado!\")\n",
    "            return\n",
    "        \n",
    "        sizes = [len(chunk) for chunk in chunks]\n",
    "        word_counts = [len(chunk.split()) for chunk in chunks]\n",
    "        \n",
    "        print(f\"ğŸ“ˆ ANÃLISE DOS CHUNKS:\")\n",
    "        print(f\"   Total de chunks: {len(chunks)}\")\n",
    "        print(f\"   Tamanho mÃ©dio: {sum(sizes)/len(sizes):.1f} caracteres\")\n",
    "        print(f\"   Tamanho min/max: {min(sizes)}/{max(sizes)} caracteres\")\n",
    "        print(f\"   Palavras mÃ©dias por chunk: {sum(word_counts)/len(word_counts):.1f}\")\n",
    "        print(f\"   ConfiguraÃ§Ã£o: chunk_size={self.chunk_size}, overlap={self.overlap}\")\n",
    "\n",
    "# ğŸš€ EXEMPLO PRÃTICO EXPANDIDO\n",
    "def exemplo_chunking_completo():\n",
    "    \"\"\"DemonstraÃ§Ã£o completa das estratÃ©gias de chunking\"\"\"\n",
    "    \n",
    "    texto_exemplo = \"\"\"\n",
    "A inteligÃªncia artificial Ã© uma Ã¡rea da ciÃªncia da computaÃ§Ã£o que se concentra \n",
    "na criaÃ§Ã£o de sistemas capazes de realizar tarefas que normalmente requerem \n",
    "inteligÃªncia humana. Isso inclui aprendizado, raciocÃ­nio, percepÃ§Ã£o e \n",
    "processamento de linguagem natural.\n",
    "\n",
    "Os embeddings sÃ£o uma tÃ©cnica fundamental em IA que converte dados categÃ³ricos \n",
    "ou textuais em representaÃ§Ãµes vetoriais densas. Essas representaÃ§Ãµes capturam \n",
    "relaÃ§Ãµes semÃ¢nticas entre os dados de forma que itens similares tenham \n",
    "representaÃ§Ãµes prÃ³ximas no espaÃ§o vetorial.\n",
    "\n",
    "O processamento de linguagem natural (NLP) utiliza essas tÃ©cnicas para \n",
    "compreender e gerar texto humano. AplicaÃ§Ãµes incluem traduÃ§Ã£o automÃ¡tica, \n",
    "anÃ¡lise de sentimentos, chatbots e sistemas de recomendaÃ§Ã£o baseados em conteÃºdo.\n",
    "\"\"\"\n",
    "    \n",
    "    print(\"ğŸ“ DEMONSTRAÃ‡ÃƒO: ESTRATÃ‰GIAS DE CHUNKING\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Configurar chunker\n",
    "    chunker = DocumentChunker(chunk_size=200, overlap=30)\n",
    "    \n",
    "    # Testar cada estratÃ©gia\n",
    "    strategies = [\n",
    "        (\"SentenÃ§as\", chunker.chunk_by_sentences),\n",
    "        (\"Tokens\", chunker.chunk_by_tokens),\n",
    "        (\"ParÃ¡grafos\", chunker.chunk_by_paragraphs)\n",
    "    ]\n",
    "    \n",
    "    for strategy_name, strategy_method in strategies:\n",
    "        print(f\"\\nğŸ” ESTRATÃ‰GIA: {strategy_name.upper()}\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        chunks = strategy_method(texto_exemplo)\n",
    "        chunker.analyze_chunks(chunks)\n",
    "        \n",
    "        print(f\"\\nğŸ“ Primeiros 2 chunks:\")\n",
    "        for i, chunk in enumerate(chunks[:2]):\n",
    "            print(f\"   Chunk {i+1}: {chunk[:100]}...\")\n",
    "            \n",
    "        # Demonstrar sobreposiÃ§Ã£o (apenas para tokens)\n",
    "        if strategy_name == \"Tokens\" and len(chunks) > 1:\n",
    "            overlap_demo = set(chunks[0].split()) & set(chunks[1].split())\n",
    "            print(f\"   ğŸ”„ Palavras em sobreposiÃ§Ã£o: {len(overlap_demo)}\")\n",
    "\n",
    "# Executar exemplo\n",
    "exemplo_chunking_completo()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c669738",
   "metadata": {},
   "source": [
    "### ğŸ¯ **Escolhendo a EstratÃ©gia Ideal**\n",
    "\n",
    "| **EstratÃ©gia** | **Melhor Para** | **Evitar Quando** |\n",
    "|----------------|-----------------|-------------------|\n",
    "| **SentenÃ§as** | Textos narrativos, artigos | SentenÃ§as muito longas |\n",
    "| **Tokens** | Controle preciso de tamanho | Contexto semÃ¢ntico Ã© crucial |\n",
    "| **ParÃ¡grafos** | Documentos estruturados | ParÃ¡grafos inconsistentes |\n",
    "\n",
    "### ğŸ”§ **ParÃ¢metros Recomendados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2174e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Para diferentes casos de uso:\n",
    "CONFIGS = {\n",
    "    'gpt-3.5': {'chunk_size': 3000, 'overlap': 300},    # ~4K tokens\n",
    "    'bert': {'chunk_size': 400, 'overlap': 50},         # ~512 tokens\n",
    "    'busca_semantica': {'chunk_size': 800, 'overlap': 100},\n",
    "    'qa_system': {'chunk_size': 1500, 'overlap': 200}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058d25ef",
   "metadata": {},
   "source": [
    "### ğŸ’¡ **Dicas AvanÃ§adas**\n",
    "\n",
    "1. **ğŸ“ MediÃ§Ã£o em Tokens**: Use tokenizadores reais em vez de caracteres\n",
    "2. **ğŸ”„ Overlap Inteligente**: Termine chunks em pontos naturais\n",
    "3. **ğŸ“Š ValidaÃ§Ã£o**: Sempre analise a qualidade dos chunks gerados\n",
    "4. **âš–ï¸ Trade-offs**: Chunks menores = mais precisÃ£o, chunks maiores = mais contexto"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
